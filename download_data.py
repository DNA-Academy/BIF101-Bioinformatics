#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
DNA Academy â€“ BIF101 Veri Ä°ndirici (Enterprise Edition v2.2 - AutoPair)

AmaÃ§:
- AynÄ± BioSample (sample_accession) Ã¼zerinden Illumina (PE) + ONT/PacBio (LR) FASTQ(.gz) indirip,
  bÃ¼yÃ¼k veriyi TAM indirmeden stream + subsample ile eÄŸitim boyutuna (MB) dÃ¼ÅŸÃ¼rmek.
- Manifest ile tam izlenebilirlik.

Not:
- ENA "filereport" ile run/sample/study + fastq_ftp alanlarÄ±nÄ± dinamik Ã§ekiyoruz.
"""

import os
import csv
import gzip
import time
import hashlib
import requests
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple

# -------------------------
# AYARLAR (SÄ°ZÄ°N HEDEFLERÄ°NÄ°Z)
# -------------------------
DATA_DIR = "data"
ENA_FILEREPORT = "https://www.ebi.ac.uk/ena/portal/api/filereport"

# Seed'ler: Ä°sterseniz bunlarÄ± bÄ±rakÄ±n; script mismatch olursa otomatik eÅŸleÅŸtirmeyi dener.
SEED_ILLUMINA_RUN = "ERR3336960"
SEED_LONGREAD_RUN = "ERR3336961"

# Ã‡Ä±ktÄ± boyut hedefleri (gz dosya boyutu)
TARGET_MB_LONG = 200   # ONT/PacBio
TARGET_MB_SHORT = 50   # Illumina R1 (R2 reads ile sync edilecek)

STRICT_SAMPLE_MATCH = True     # premium kural
AUTO_REPAIR_ON_MISMATCH = True # mismatch ise otomatik Ã§Ã¶zÃ¼mle

MANIFEST_FILE = os.path.join(DATA_DIR, "manifest.tsv")

# ENA platform kodlarÄ±
PLATFORM_ILLUMINA = "ILLUMINA"
PLATFORM_LONGREADS = ("OXFORD_NANOPORE", "PACBIO_SMRT")

# -------------------------
# VERÄ° YAPISI
# -------------------------
@dataclass
class EnaRun:
    run_accession: str
    sample_accession: str
    study_accession: str
    scientific_name: str
    strain: str
    instrument_platform: str
    instrument_model: str
    library_layout: str
    fastq_urls: List[str]
    fastq_bytes: Optional[int] = None

# -------------------------
# GENEL YARDIMCILAR
# -------------------------
def ftp_path_to_https(url_or_path: str) -> str:
    s = (url_or_path or "").strip()
    if s.startswith("ftp://"):
        s = s[len("ftp://"):]
    if s.startswith("http://"):
        s = "https://" + s[len("http://"):]
    if s.startswith("https://"):
        return s
    return "https://" + s

def parse_sizes(s: str) -> Optional[int]:
    # ENA bazen ";" ile Ã§oklu dosya boyutu dÃ¶ner (PE vb.)
    parts = [p.strip() for p in (s or "").split(";") if p.strip().isdigit()]
    return sum(int(x) for x in parts) if parts else None

def sha256_file(path: str) -> str:
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for b in iter(lambda: f.read(1024 * 1024), b""):
            h.update(b)
    return h.hexdigest()

def now_iso() -> str:
    return time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

# -------------------------
# HTTP RETRY
# -------------------------
def http_get_with_retries(
    session: requests.Session,
    url: str,
    *,
    stream: bool = True,
    retries: int = 4,
    backoff: float = 2.0,
    headers: Optional[dict] = None,
    timeout: Tuple[int, int] = (10, 180),
) -> requests.Response:
    headers = headers or {}
    last_err = None
    for attempt in range(1, retries + 2):
        try:
            r = session.get(url, stream=stream, timeout=timeout, allow_redirects=True, headers=headers)
            if r.status_code in (429, 500, 502, 503, 504):
                r.close()
                time.sleep(backoff * attempt)
                continue
            r.raise_for_status()
            return r
        except requests.RequestException as e:
            last_err = e
            if attempt <= retries:
                time.sleep(backoff * attempt)
                continue
            break
    raise RuntimeError(f"HTTP baÅŸarÄ±sÄ±z: {url} | Hata: {last_err}")

# -------------------------
# ENA API
# -------------------------
def ena_filereport(session: requests.Session, accession: str, fields: str, result: str = "read_run") -> List[Dict[str, str]]:
    params = {
        "accession": accession,
        "result": result,
        "fields": fields,
        "format": "tsv",
    }
    r = http_get_with_retries(session, ENA_FILEREPORT, stream=False, retries=3, backoff=2.0, timeout=(10, 60), headers=None)
    # YukarÄ±daki satÄ±r ENA_FILEREPORT'a yanlÄ±ÅŸ olur: url sabit, param lazÄ±m.
    # requests.get paramlarÄ± iÃ§in ayrÄ± Ã§aÄŸrÄ± yapalÄ±m:
    r.close()
    try:
        rr = session.get(ENA_FILEREPORT, params=params, timeout=(10, 60))
        rr.raise_for_status()
        lines = rr.text.strip().splitlines()
        if len(lines) < 2:
            return []
        return list(csv.DictReader(lines, delimiter="\t"))
    except Exception as e:
        print(f"âš ï¸ ENA filereport hatasÄ± ({accession}): {e}")
        return []

def get_run_info(session: requests.Session, run_accession: str) -> Optional[EnaRun]:
    print(f"ğŸ” Metadata sorgulanÄ±yor: {run_accession} ...")
    fields = ",".join([
        "run_accession",
        "sample_accession",
        "study_accession",
        "scientific_name",
        "strain",
        "instrument_platform",
        "instrument_model",
        "library_layout",
        "fastq_ftp",
        "fastq_bytes",
    ])
    recs = ena_filereport(session, run_accession, fields=fields, result="read_run")
    if not recs:
        return None
    rec = recs[0]
    urls = [ftp_path_to_https(u) for u in (rec.get("fastq_ftp") or "").split(";") if u.strip()]
    return EnaRun(
        run_accession=rec.get("run_accession", run_accession),
        sample_accession=rec.get("sample_accession", ""),
        study_accession=rec.get("study_accession", ""),
        scientific_name=rec.get("scientific_name", "Unknown"),
        strain=rec.get("strain", ""),
        instrument_platform=rec.get("instrument_platform", ""),
        instrument_model=rec.get("instrument_model", ""),
        library_layout=rec.get("library_layout", ""),
        fastq_urls=urls,
        fastq_bytes=parse_sizes(rec.get("fastq_bytes") or ""),
    )

def list_runs_for_sample(session: requests.Session, sample_accession: str) -> List[EnaRun]:
    fields = ",".join([
        "run_accession",
        "sample_accession",
        "study_accession",
        "scientific_name",
        "strain",
        "instrument_platform",
        "instrument_model",
        "library_layout",
        "fastq_ftp",
        "fastq_bytes",
    ])
    recs = ena_filereport(session, sample_accession, fields=fields, result="read_run")
    runs = []
    for rec in recs:
        urls = [ftp_path_to_https(u) for u in (rec.get("fastq_ftp") or "").split(";") if u.strip()]
        if not urls:
            continue
        runs.append(EnaRun(
            run_accession=rec.get("run_accession", ""),
            sample_accession=rec.get("sample_accession", sample_accession),
            study_accession=rec.get("study_accession", ""),
            scientific_name=rec.get("scientific_name", "Unknown"),
            strain=rec.get("strain", ""),
            instrument_platform=rec.get("instrument_platform", ""),
            instrument_model=rec.get("instrument_model", ""),
            library_layout=rec.get("library_layout", ""),
            fastq_urls=urls,
            fastq_bytes=parse_sizes(rec.get("fastq_bytes") or ""),
        ))
    return runs

def list_runs_for_study(session: requests.Session, study_accession: str) -> List[EnaRun]:
    fields = ",".join([
        "run_accession",
        "sample_accession",
        "study_accession",
        "scientific_name",
        "strain",
        "instrument_platform",
        "instrument_model",
        "library_layout",
        "fastq_ftp",
        "fastq_bytes",
    ])
    recs = ena_filereport(session, study_accession, fields=fields, result="read_run")
    runs = []
    for rec in recs:
        urls = [ftp_path_to_https(u) for u in (rec.get("fastq_ftp") or "").split(";") if u.strip()]
        if not urls:
            continue
        runs.append(EnaRun(
            run_accession=rec.get("run_accession", ""),
            sample_accession=rec.get("sample_accession", ""),
            study_accession=rec.get("study_accession", study_accession),
            scientific_name=rec.get("scientific_name", "Unknown"),
            strain=rec.get("strain", ""),
            instrument_platform=rec.get("instrument_platform", ""),
            instrument_model=rec.get("instrument_model", ""),
            library_layout=rec.get("library_layout", ""),
            fastq_urls=urls,
            fastq_bytes=parse_sizes(rec.get("fastq_bytes") or ""),
        ))
    return runs

# -------------------------
# RUN SEÃ‡Ä°MÄ° (PREMIUM)
# -------------------------
def pick_best_illumina(runs: List[EnaRun]) -> Optional[EnaRun]:
    cands = []
    for r in runs:
        if r.instrument_platform != PLATFORM_ILLUMINA:
            continue
        # PE tercih
        pe_bonus = 0 if (r.library_layout.upper() == "PAIRED" and len(r.fastq_urls) >= 2) else 1
        size = r.fastq_bytes if r.fastq_bytes is not None else 10**18
        cands.append((pe_bonus, size, r))
    if not cands:
        return None
    cands.sort(key=lambda x: (x[0], x[1]))
    return cands[0][2]

def pick_best_longread(runs: List[EnaRun]) -> Optional[EnaRun]:
    cands = []
    for r in runs:
        if r.instrument_platform not in PLATFORM_LONGREADS:
            continue
        # ONT Ã¶ncelik
        plat_bonus = 0 if r.instrument_platform == "OXFORD_NANOPORE" else 1
        size = r.fastq_bytes if r.fastq_bytes is not None else 10**18
        cands.append((plat_bonus, size, r))
    if not cands:
        return None
    cands.sort(key=lambda x: (x[0], x[1]))
    return cands[0][2]

def detect_r1_r2(urls: List[str]) -> Tuple[str, str]:
    # ENA naming genelde *_1.fastq.gz / *_2.fastq.gz
    r1 = next((u for u in urls if "_1.fastq" in u), None)
    r2 = next((u for u in urls if "_2.fastq" in u), None)
    if not r1 and urls:
        r1 = urls[0]
    if not r2 and len(urls) >= 2:
        r2 = urls[1]
    if not r1 or not r2:
        raise RuntimeError("Illumina iÃ§in R1/R2 URL tespiti baÅŸarÄ±sÄ±z.")
    return r1, r2

def resolve_pair(session: requests.Session, ill: EnaRun, lr: EnaRun) -> Tuple[EnaRun, EnaRun]:
    # Zaten eÅŸleÅŸiyorsa bitir
    if ill.sample_accession and lr.sample_accession and ill.sample_accession == lr.sample_accession:
        print(f"âœ… Numune EÅŸleÅŸmesi: {ill.sample_accession}")
        return ill, lr

    print(f"âŒ KRÄ°TÄ°K: Numuneler eÅŸleÅŸmiyor! Illumina={ill.sample_accession} vs LR={lr.sample_accession}")

    if not AUTO_REPAIR_ON_MISMATCH:
        if STRICT_SAMPLE_MATCH:
            raise RuntimeError("Sample mismatch (AUTO_REPAIR kapalÄ±).")
        return ill, lr

    # 1) Illumina sample'Ä±nda long-read var mÄ±?
    if ill.sample_accession:
        runs = list_runs_for_sample(session, ill.sample_accession)
        lr2 = pick_best_longread(runs)
        if lr2:
            print(f"ğŸ”§ AutoRepair: Illumina sample iÃ§inde LR bulundu: {lr2.run_accession}")
            return ill, lr2

    # 2) Long-read sample'Ä±nda Illumina var mÄ±?
    if lr.sample_accession:
        runs = list_runs_for_sample(session, lr.sample_accession)
        ill2 = pick_best_illumina(runs)
        if ill2:
            print(f"ğŸ”§ AutoRepair: LR sample iÃ§inde Illumina bulundu: {ill2.run_accession}")
            return ill2, lr

    # 3) Study iÃ§inde paired sample ara
    study = ill.study_accession or lr.study_accession
    if study:
        print(f"ğŸ”§ AutoRepair: Study iÃ§inde paired sample aranÄ±yor: {study}")
        all_runs = list_runs_for_study(session, study)
        by_sample: Dict[str, List[EnaRun]] = {}
        for r in all_runs:
            if r.sample_accession:
                by_sample.setdefault(r.sample_accession, []).append(r)

        candidates: List[Tuple[int, int, str, EnaRun, EnaRun]] = []
        for sacc, rs in by_sample.items():
            i = pick_best_illumina(rs)
            l = pick_best_longread(rs)
            if i and l:
                size_i = i.fastq_bytes or 10**18
                size_l = l.fastq_bytes or 10**18
                candidates.append((size_i + size_l, size_l, sacc, i, l))

        if candidates:
            candidates.sort(key=lambda x: (x[0], x[1]))
            _, __, sacc, i, l = candidates[0]
            print(f"âœ… AutoRepair: Paired sample seÃ§ildi: {sacc} | Illumina={i.run_accession} | LR={l.run_accession}")
            return i, l

    if STRICT_SAMPLE_MATCH:
        raise RuntimeError("AutoRepair baÅŸarÄ±sÄ±z: aynÄ± sample iÃ§inde Illumina+LongRead bulunamadÄ±.")
    return ill, lr

# -------------------------
# STREAM SUBSAMPLE
# -------------------------
def stream_subsample_gz(
    session: requests.Session,
    url: str,
    out_path: str,
    *,
    mode: str,         # "MB" or "READS"
    target: int,       # MB veya read sayÄ±sÄ±
    check_every_reads: int = 5000
) -> int:
    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
    tmp = out_path + ".part"

    headers = {"Accept-Encoding": "identity"}  # HTTP-level gzip'i kapat, file zaten .gz
    max_bytes = int(target * 1024 * 1024) if mode == "MB" else None

    read_count = 0
    line_count = 0

    print(f"â¬‡ï¸  Streaming: {os.path.basename(out_path)} | mode={mode} target={target}")
    print(f"    -> {url}")

    r = http_get_with_retries(session, url, stream=True, retries=4, backoff=2.0, headers=headers, timeout=(10, 240))
    try:
        r.raw.decode_content = False
        gz_in = gzip.GzipFile(fileobj=r.raw)

        with gzip.open(tmp, "wb") as gz_out:
            while True:
                line = gz_in.readline()
                if not line:
                    break

                gz_out.write(line)
                line_count += 1

                if line_count % 4 == 0:
                    read_count += 1

                    if mode == "READS" and read_count >= target:
                        break

                    if mode == "MB" and (read_count % check_every_reads == 0):
                        gz_out.flush()
                        if os.path.getsize(tmp) >= max_bytes:
                            break

        os.replace(tmp, out_path)
        final_mb = os.path.getsize(out_path) / (1024 * 1024)
        print(f"    âœ… OK: reads={read_count} | size={final_mb:.2f} MB")
        return read_count

    except Exception as e:
        print(f"    âŒ Streaming hata: {e}")
        if os.path.exists(tmp):
            os.remove(tmp)
        return 0
    finally:
        r.close()

# -------------------------
# MANIFEST
# -------------------------
def manifest_write_header_if_needed():
    if os.path.exists(MANIFEST_FILE):
        return
    os.makedirs(DATA_DIR, exist_ok=True)
    with open(MANIFEST_FILE, "w", newline="") as f:
        w = csv.writer(f, delimiter="\t")
        w.writerow([
            "created_utc",
            "filename",
            "type",
            "run_accession",
            "sample_accession",
            "study_accession",
            "platform",
            "model",
            "library_layout",
            "organism",
            "strain",
            "source_url",
            "reads",
            "output_mb",
            "sha256",
        ])

def manifest_append(run: EnaRun, filename: str, filetype: str, source_url: str, reads: int):
    path = os.path.join(DATA_DIR, filename)
    manifest_write_header_if_needed()
    out_mb = os.path.getsize(path) / (1024 * 1024)
    sha = sha256_file(path)

    with open(MANIFEST_FILE, "a", newline="") as f:
        w = csv.writer(f, delimiter="\t")
        w.writerow([
            now_iso(),
            filename,
            filetype,
            run.run_accession,
            run.sample_accession,
            run.study_accession,
            run.instrument_platform,
            run.instrument_model,
            run.library_layout,
            run.scientific_name,
            run.strain,
            source_url,
            reads,
            f"{out_mb:.2f}",
            sha,
        ])

# -------------------------
# MAIN
# -------------------------
def main():
    os.makedirs(DATA_DIR, exist_ok=True)
    if os.path.exists(MANIFEST_FILE):
        os.remove(MANIFEST_FILE)

    session = requests.Session()

    print("ğŸš€ BIF101 Enterprise Veri Ä°ndirici (v2.2 AutoPair)\n")

    ill = get_run_info(session, SEED_ILLUMINA_RUN)
    lr = get_run_info(session, SEED_LONGREAD_RUN)

    if not ill or not lr:
        raise SystemExit("âŒ Seed metadata alÄ±namadÄ±. Seed accession'larÄ± kontrol edin.")

    # Premium: AutoPair / strict sample validation
    ill, lr = resolve_pair(session, ill, lr)

    print("\n--- Ä°NDÄ°RME BAÅLIYOR ---\n")

    # Illumina PE: R1 boyuta gÃ¶re, R2 read sayÄ±sÄ±na gÃ¶re sync
    if ill.instrument_platform == PLATFORM_ILLUMINA:
        r1_url, r2_url = detect_r1_r2(ill.fastq_urls)

        prefix = f"{ill.run_accession}_ILLUMINA_{TARGET_MB_SHORT}MB"
        r1_name = f"{prefix}_R1.fastq.gz"
        r2_name = f"{prefix}_R2.fastq.gz"

        reads_r1 = stream_subsample_gz(session, r1_url, os.path.join(DATA_DIR, r1_name), mode="MB", target=TARGET_MB_SHORT)
        if reads_r1 > 0:
            manifest_append(ill, r1_name, "Short-PE-R1", r1_url, reads_r1)

            reads_r2 = stream_subsample_gz(session, r2_url, os.path.join(DATA_DIR, r2_name), mode="READS", target=reads_r1)
            if reads_r2 > 0:
                manifest_append(ill, r2_name, "Short-PE-R2", r2_url, reads_r2)
        else:
            print("âŒ Illumina R1 indirilemedi.")
    else:
        print(f"âš ï¸ SeÃ§ilen short-run Illumina deÄŸil: {ill.instrument_platform}")

    print("-" * 60)

    # Long read: boyuta gÃ¶re subset
    if lr.instrument_platform in PLATFORM_LONGREADS and lr.fastq_urls:
        plat_tag = "ONT" if lr.instrument_platform == "OXFORD_NANOPORE" else "PACBIO"
        lr_name = f"{lr.run_accession}_{plat_tag}_{TARGET_MB_LONG}MB.fastq.gz"
        lr_url = lr.fastq_urls[0]

        reads_lr = stream_subsample_gz(session, lr_url, os.path.join(DATA_DIR, lr_name), mode="MB", target=TARGET_MB_LONG)
        if reads_lr > 0:
            manifest_append(lr, lr_name, "Long-Read", lr_url, reads_lr)
        else:
            print("âŒ Long-read indirilemedi.")
    else:
        print(f"âŒ Long-run uygun deÄŸil veya URL yok: {lr.instrument_platform}")

    print(f"\nğŸ‰ TamamlandÄ±. Manifest: {MANIFEST_FILE}")

if __name__ == "__main__":
    main()
